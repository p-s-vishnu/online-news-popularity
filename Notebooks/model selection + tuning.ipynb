{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings ( \"ignore\" )\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score , roc_auc_score , confusion_matrix , classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv ( \"train.csv\" )\n",
    "test = pd.read_csv ( \"test.csv\" )\n",
    "\n",
    "X_train = train.drop ( \"Popularity\" , axis = 1 )\n",
    "y_train = train [ \"Popularity\" ]\n",
    "X_test = test.drop ( \"Popularity\" , axis = 1 )\n",
    "y_test = test [ \"Popularity\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\":LogisticRegression(random_state=5,n_jobs=-1),\n",
    "    \"SGDClassifier\":SGDClassifier(random_state=5,n_jobs=-1),\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier(random_state=5),\n",
    "    \"RandomForestClassifier\":RandomForestClassifier(random_state=5,n_jobs=-1),\n",
    "    \"GaussianNB\":GaussianNB(random_state=5),\n",
    "    \"KNeighborsClassifier\":KNeighborsClassifier(random_state=5,n_jobs=-1),\n",
    "    \"AdaBoostClassifier\":AdaBoostClassifier(random_state=5),\n",
    "    \"GradientBoostingClassifier\":GradientBoostingClassifier(),\n",
    "    \"XGBClassifier\":XGBClassifier(random_state=5),\n",
    "    \"BaggingClassifier\":BaggingClassifier(n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(X_train,y_train,models):\n",
    "    train_results ,test_results = [],[]\n",
    "    print(f'Using {len(X_train.columns)} features...')\n",
    "    for _,model in tqdm(models.items()):\n",
    "        model.fit(X_train,y_train)\n",
    "        train_predict = model.predict ( X_train )\n",
    "        test_predict = model.predict ( X_test )\n",
    "        train_results.append ( accuracy_score ( y_train , train_predict ) )\n",
    "        test_results.append ( accuracy_score ( y_test , test_predict ) )\n",
    "        \n",
    "    comparison = pd.DataFrame ( )\n",
    "    comparison ['model'] = models.keys()\n",
    "    comparison [ \"Train Score\" ] = train_results\n",
    "    comparison [ \"Test Score\" ] = test_results\n",
    "    print(comparison.sort_values(by=\"Test Score\",ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 58 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:33<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model  Train Score  Test Score\n",
      "8               XGBClassifier     0.684541    0.656970\n",
      "7  GradientBoostingClassifier     0.684901    0.655288\n",
      "6          AdaBoostClassifier     0.664937    0.649655\n",
      "3      RandomForestClassifier     0.983820    0.620397\n",
      "9           BaggingClassifier     0.984973    0.619472\n",
      "0          LogisticRegression     0.607892    0.609887\n",
      "2      DecisionTreeClassifier     1.000000    0.577266\n",
      "4                  GaussianNB     0.572577    0.577098\n",
      "5        KNeighborsClassifier     0.718739    0.567261\n",
      "1               SGDClassifier     0.518054    0.522953\n"
     ]
    }
   ],
   "source": [
    "compare_models(X_train,y_train,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing highly correlated values as per the insights from EDA\n",
    "# n_non_stop_words, n_non_stop_unique_tokens, n_unique_token\n",
    "# is_weekend\n",
    "# kw_max_avg\n",
    "highcorr=['n_non_stop_words','n_non_stop_unique_tokens','is_weekend','kw_max_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def run_rfe(X_train , y_train, model):\n",
    "    rfc=model.fit(X_train,y_train)\n",
    "    rfe = RFE ( rfc , n_features_to_select = 3, verbose=2 )\n",
    "    rfe.fit ( X_train , y_train )\n",
    "    return rfe\n",
    "    \n",
    "rfe = run_rfe(X_train , y_train,XGBClassifier(random_state=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14            data_channel_is_world\n",
       "10    data_channel_is_entertainment\n",
       "13             data_channel_is_tech\n",
       "15                       kw_min_min\n",
       "22                       kw_avg_avg\n",
       "23        self_reference_min_shares\n",
       "25       self_reference_avg_sharess\n",
       "21                       kw_min_avg\n",
       "45            min_positive_polarity\n",
       "5                          num_imgs\n",
       "17                       kw_avg_min\n",
       "18                       kw_min_max\n",
       "3                         num_hrefs\n",
       "19                       kw_max_max\n",
       "20                       kw_avg_max\n",
       "29              weekday_is_thursday\n",
       "27               weekday_is_tuesday\n",
       "28             weekday_is_wednesday\n",
       "35                           LDA_02\n",
       "2                   n_unique_tokens\n",
       "Name: Columns, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame ( { \"Columns\" : X_train.columns , \n",
    "               \"Support\" : rfe.support_  , \n",
    "             \"Ranking\" : rfe.ranking_ } )\n",
    "d.sort_values(by=\"Ranking\",inplace=True)\n",
    "\n",
    "n = 20\n",
    "d['Columns'][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = d['Columns'][:n]\n",
    "\n",
    "X_train = train[selected]\n",
    "y_train = train [ \"Popularity\" ]\n",
    "X_test = test[selected]\n",
    "y_test = test [ \"Popularity\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model  Train Score  Test Score\n",
      "7  GradientBoostingClassifier     0.675315    0.654868\n",
      "8               XGBClassifier     0.674919    0.654700\n",
      "6          AdaBoostClassifier     0.658054    0.647637\n",
      "3      RandomForestClassifier     0.983495    0.610896\n",
      "9           BaggingClassifier     0.982126    0.605095\n",
      "0          LogisticRegression     0.602919    0.601648\n",
      "4                  GaussianNB     0.582198    0.581722\n",
      "2      DecisionTreeClassifier     1.000000    0.564907\n",
      "5        KNeighborsClassifier     0.721586    0.564486\n",
      "1               SGDClassifier     0.495928    0.491172\n"
     ]
    }
   ],
   "source": [
    "compare_models(X_train,y_train,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 15 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model  Train Score  Test Score\n",
      "8               XGBClassifier     0.665189    0.652262\n",
      "7  GradientBoostingClassifier     0.665838    0.646797\n",
      "6          AdaBoostClassifier     0.651784    0.637885\n",
      "3      RandomForestClassifier     0.982919    0.607870\n",
      "9           BaggingClassifier     0.982775    0.606524\n",
      "0          LogisticRegression     0.604216    0.601564\n",
      "4                  GaussianNB     0.582018    0.581638\n",
      "2      DecisionTreeClassifier     1.000000    0.568438\n",
      "5        KNeighborsClassifier     0.721586    0.564486\n",
      "1               SGDClassifier     0.495928    0.491172\n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "# print(d['Columns'][:n])\n",
    "selected = d['Columns'][:n]\n",
    "\n",
    "X_train = train[selected]\n",
    "y_train = train [ \"Popularity\" ]\n",
    "X_test = test[selected]\n",
    "y_test = test [ \"Popularity\" ]\n",
    "compare_models(X_train,y_train,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change is_monday, etc to days\n",
    "\n",
    "def week_encode(msg):\n",
    "    if msg.endswith('monday'):\n",
    "        return 1\n",
    "    elif msg.endswith('tuesday'):\n",
    "        return 2\n",
    "    elif msg.endswith('wednesday'):\n",
    "        return 3\n",
    "    elif msg.endswith('thursday'):\n",
    "        return 4\n",
    "    elif msg.endswith('friday'):\n",
    "        return 5\n",
    "    elif msg.endswith('saturday'):\n",
    "        return 6\n",
    "    elif msg.endswith('sunday'):\n",
    "        return 7\n",
    "    else: \n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature - Day\n",
    "train1 = train.copy()\n",
    "test1 = test.copy()\n",
    "\n",
    "weeks = [\"weekday_is_monday\", \"weekday_is_tuesday\", \"weekday_is_wednesday\",\n",
    "\"weekday_is_thursday\", \"weekday_is_friday\", \"weekday_is_saturday\",\n",
    "\"weekday_is_sunday\"]\n",
    "\n",
    "\n",
    "train1['day'] = train1.apply(lambda x: week_encode(np.argmax(x[weeks])),axis=1)\n",
    "test1['day'] = test1.apply(lambda x: week_encode(np.argmax(x[weeks])),axis=1)\n",
    "\n",
    "train1.drop(columns = highcorr+weeks,inplace=True)\n",
    "test1.drop(columns = highcorr+weeks,inplace=True)\n",
    "\n",
    "X_train = train1.drop ( \"Popularity\" , axis = 1 )\n",
    "y_train = train1 [ \"Popularity\" ]\n",
    "X_test = test1.drop ( \"Popularity\" , axis = 1 )\n",
    "y_test = test1 [ \"Popularity\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n"
     ]
    }
   ],
   "source": [
    "rfe=run_rfe(X_train,y_train,XGBClassifier(random_state=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top N features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14            data_channel_is_world\n",
      "13             data_channel_is_tech\n",
      "10    data_channel_is_entertainment\n",
      "15                       kw_min_min\n",
      "22                       kw_avg_avg\n",
      "23        self_reference_min_shares\n",
      "47                              day\n",
      "25       self_reference_avg_sharess\n",
      "2                   n_unique_tokens\n",
      "38            min_positive_polarity\n",
      "3                         num_hrefs\n",
      "20                       kw_avg_max\n",
      "17                       kw_avg_min\n",
      "19                       kw_max_max\n",
      "18                       kw_min_max\n",
      "21                       kw_min_avg\n",
      "28                           LDA_02\n",
      "31              global_subjectivity\n",
      "27                           LDA_01\n",
      "5                          num_imgs\n",
      "Name: Columns, dtype: object\n"
     ]
    }
   ],
   "source": [
    "d = pd.DataFrame ( { \"Columns\" : X_train.columns , \n",
    "               \"Support\" : rfe.support_  , \n",
    "             \"Ranking\" : rfe.ranking_ } )\n",
    "d.sort_values(by=\"Ranking\",inplace=True)\n",
    "\n",
    "n = 20\n",
    "print(d['Columns'][:n])\n",
    "selected = d['Columns'][:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model  Train Score  Test Score\n",
      "8               XGBClassifier     0.676685    0.650748\n",
      "7  GradientBoostingClassifier     0.676144    0.650244\n",
      "6          AdaBoostClassifier     0.659856    0.645788\n",
      "9           BaggingClassifier     0.984649    0.610224\n",
      "0          LogisticRegression     0.605297    0.604170\n",
      "3      RandomForestClassifier     0.984324    0.601900\n",
      "4                  GaussianNB     0.582523    0.580881\n",
      "1               SGDClassifier     0.577261    0.580209\n",
      "5        KNeighborsClassifier     0.721586    0.564486\n",
      "2      DecisionTreeClassifier     1.000000    0.558265\n"
     ]
    }
   ],
   "source": [
    "X_train = train1[selected]\n",
    "y_train = train1 [ \"Popularity\" ]\n",
    "X_test = test1[selected]\n",
    "y_test = test1 [ \"Popularity\" ]\n",
    "compare_models(X_train,y_train,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data_channel_is_lifestyle', 'data_channel_is_entertainment',\n",
      "       'data_channel_is_bus', 'data_channel_is_socmed', 'data_channel_is_tech',\n",
      "       'data_channel_is_world'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "channels = train.loc[:,\"data_channel_is_lifestyle\":\"data_channel_is_world\"].columns\n",
    "print(channels)\n",
    "\n",
    "def channel_encode(msg):\n",
    "    if msg.endswith('lifestyle'):\n",
    "        return 1\n",
    "    elif msg.endswith('entertainment'):\n",
    "        return 2\n",
    "    elif msg.endswith('bus'):\n",
    "        return 3\n",
    "    elif msg.endswith('socmed'):\n",
    "        return 4\n",
    "    elif msg.endswith('tech'):\n",
    "        return 5\n",
    "    elif msg.endswith('world'):\n",
    "        return 6\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature - Day\n",
    "train1['channels'] = train1.apply(lambda x: channel_encode(np.argmax(x[channels])),axis=1)\n",
    "test1['channels'] = test1.apply(lambda x: channel_encode(np.argmax(x[channels])),axis=1)\n",
    "\n",
    "# drop various channels\n",
    "for df in [train1,test1]:\n",
    "    df.drop(columns=channels,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train1.drop ( \"Popularity\" , axis = 1 )\n",
    "y_train = train1 [ \"Popularity\" ]\n",
    "X_test = test1.drop ( \"Popularity\" , axis = 1 )\n",
    "y_test = test1 [ \"Popularity\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n"
     ]
    }
   ],
   "source": [
    "rfe=run_rfe(X_train,y_train,XGBClassifier(random_state=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42                      channels\n",
      "17     self_reference_min_shares\n",
      "16                    kw_avg_avg\n",
      "41                           day\n",
      "9                     kw_min_min\n",
      "19    self_reference_avg_sharess\n",
      "24                        LDA_04\n",
      "32         min_positive_polarity\n",
      "15                    kw_min_avg\n",
      "13                    kw_max_max\n",
      "2                n_unique_tokens\n",
      "3                      num_hrefs\n",
      "21                        LDA_01\n",
      "20                        LDA_00\n",
      "14                    kw_avg_max\n",
      "11                    kw_avg_min\n",
      "22                        LDA_02\n",
      "12                    kw_min_max\n",
      "5                       num_imgs\n",
      "25           global_subjectivity\n",
      "Name: Columns, dtype: object\n"
     ]
    }
   ],
   "source": [
    "d = pd.DataFrame ( { \"Columns\" : X_train.columns , \n",
    "               \"Support\" : rfe.support_  , \n",
    "             \"Ranking\" : rfe.ranking_ } )\n",
    "d.sort_values(by=\"Ranking\",inplace=True)\n",
    "\n",
    "n = 20\n",
    "print(d['Columns'][:n])\n",
    "selected = d['Columns'][:n]\n",
    "\n",
    "X_train = train1[selected]\n",
    "y_train = train1 [ \"Popularity\" ]\n",
    "X_test = test1[selected]\n",
    "y_test = test1 [ \"Popularity\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n",
      "\n",
      " 10%|████████▎                                                                          | 1/10 [00:00<00:07,  1.15it/s]\n",
      "\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:02<00:07,  1.01it/s]\n",
      "\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:02<00:06,  1.14it/s]\n",
      "\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:03<00:04,  1.34it/s]\n",
      "\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:05<00:03,  1.21it/s]\n",
      "\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:08<00:04,  1.45s/it]\n",
      "\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:11<00:04,  2.13s/it]\n",
      "\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:15<00:02,  2.64s/it]\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model  Train Score  Test Score\n",
      "8               XGBClassifier     0.673910    0.648730\n",
      "7  GradientBoostingClassifier     0.675568    0.645367\n",
      "6          AdaBoostClassifier     0.657766    0.637296\n",
      "3      RandomForestClassifier     0.984000    0.610896\n",
      "0          LogisticRegression     0.605910    0.605179\n",
      "9           BaggingClassifier     0.983243    0.604086\n",
      "4                  GaussianNB     0.582162    0.580797\n",
      "2      DecisionTreeClassifier     1.000000    0.568438\n",
      "5        KNeighborsClassifier     0.721586    0.564486\n",
      "1               SGDClassifier     0.503387    0.497057\n"
     ]
    }
   ],
   "source": [
    "compare_models(X_train,y_train,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model  Train Score  Test Score\n",
      "7  GradientBoostingClassifier     0.636360    0.613334\n",
      "8               XGBClassifier     0.632973    0.613250\n",
      "6          AdaBoostClassifier     0.616973    0.608626\n",
      "0          LogisticRegression     0.592757    0.591307\n",
      "3      RandomForestClassifier     0.982559    0.571885\n",
      "4                  GaussianNB     0.559495    0.562637\n",
      "1               SGDClassifier     0.565117    0.560955\n",
      "9           BaggingClassifier     0.981045    0.560367\n",
      "5        KNeighborsClassifier     0.710126    0.553809\n",
      "2      DecisionTreeClassifier     1.000000    0.541365\n"
     ]
    }
   ],
   "source": [
    "compare_models(X_train,y_train,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing highly correlated values as per the insights from EDA\n",
    "\n",
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
